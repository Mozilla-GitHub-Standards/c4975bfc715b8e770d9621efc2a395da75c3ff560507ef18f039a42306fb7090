
# DNS Records the the important entry-points in the stack. 
# Each entry embeds the shared DNSPrefix parameter, to allow multiple deploys.
#
#    logs.<prefix>.lcip.org:     log collection server
#    api-accounts.<prefix>.lcip.org:      loadbalancer fronting webheads
#    scrypt-accounts.<prefix>.lcip.org:   loadbalancer fronting scrypt nodes
#    db.<prefix>.lcip.org:       public alias for the MySQL database
#    loads.<prefix>.lcip.org:    loads broker for submitting loadtest jobs

DNSRecords:
  Type: AWS::Route53::RecordSetGroup
  Properties:
    HostedZoneName: "lcip.org."
    RecordSets:
      - Name: {"Fn::Join": [".", ["logs", {"Ref": "DNSPrefix"}, "lcip.org."]]}
        Type: CNAME
        TTL: "30"
        ResourceRecords:
          - {"Fn::GetAtt": ["LogServer", "PublicDnsName"]}
      - Name: {"Fn::Join": [".", ["api-accounts", {"Ref":"DNSPrefix"}, "lcip.org."]]}
        Type: CNAME
        TTL: "30"
        ResourceRecords:
          - {"Fn::GetAtt": ["IdpLoadBalancer", "DNSName"]}
      - Name: {"Fn::Join": [".", ["db", {"Ref":"DNSPrefix"}, "lcip.org."]]}
        Type: CNAME
        TTL: "30"
        ResourceRecords:
          - {"Fn::GetAtt": ["Database", "Endpoint.Address"]}
      - Name: {"Fn::Join": [".", ["scrypt-accounts", {"Ref":"DNSPrefix"}, "lcip.org."]]}
        Type: CNAME
        TTL: "30"
        ResourceRecords:
          - {"Fn::GetAtt": ["ScryptLoadBalancer", "DNSName"]}
      - Name: {"Fn::Join": [".", ["loads", {"Ref":"DNSPrefix"}, "lcip.org."]]}
        Type: CNAME
        TTL: "30"
        ResourceRecords:
          - {"Fn::GetAtt": ["LoadsBroker", "PublicDnsName"]}


# The log-collecting server, and associated infra.
# It's just a stand-alone box.

LogServer:
  Type: AWS::EC2::Instance
  Properties:
    # This needs a hekuva lotta CPU to keep up with all the logs...
    InstanceType: m1.xlarge
    ImageId: { "Ref": "LogBoxAMI" }
    KeyName: { "Ref": "AWSBoxDeployKey" }
    SecurityGroups:
      - {"Ref": "LogServerSecurityGroup"}
    BlockDeviceMappings:
      - DeviceName: "/dev/sdb"
        VirtualName: "ephemeral0"
    UserData: {"Fn::Base64": {"Fn::Join": ["", [
      "#!/bin/bash\n",
      "set -e -x\n",
      # Symlink ephemeral storage onto /var/data, preserving contents.
      "tar -cjvf /tmp/datadir.tar.bz2 /var/data/elasticsearch\n",
      "rm -rf /var/data\n",
      "ln -s /media/ephemeral0 /var/data\n",
      "tar -xjvf /tmp/datadir.tar.bz2 -C /\n",
      "rm /tmp/datadir.tar.bz2\n",
      # Execute local startup after cloudinit has run.
      "mv /etc/rc.local.post-cloudinit /etc/rc.local\n",
      "exec /etc/rc.local\n",
       ]]}}


LogServerSecurityGroup:
  Type: AWS::EC2::SecurityGroup
  Properties:
    GroupDescription: "awsboxen security group for log-collecting server"
    SecurityGroupIngress:
      - IpProtocol: "tcp"
        FromPort: "22"
        ToPort: "22"
        CidrIp: "0.0.0.0/0"
      # Allow inbound web traffic from anywhere.
      - IpProtocol: "tcp"
        FromPort: "80"
        ToPort: "80"
        CidrIp: "0.0.0.0/0"
      - IpProtocol: "tcp"
        FromPort: "443"
        ToPort: "443"
        CidrIp: "0.0.0.0/0"
      # Allow ElasticSearch access, for the  kibana web interface.
      - IpProtocol: "tcp"
        FromPort: "9200"
        ToPort: "9200"
        CidrIp: "0.0.0.0/0"
      # Allow access to heka web dashboard.
      - IpProtocol: "tcp"
        FromPort: "4352"
        ToPort: "4352"
        CidrIp: "0.0.0.0/0"
      # Allow inbound heka logs from the other resources in this stack.
      # XXX TODO: lock down these ports a little more...
      - IpProtocol: "tcp"
        FromPort: "5000"
        ToPort: "12000"
        SourceSecurityGroupName: {"Ref": "HekaClientSecurityGroup"}


HekaClientSecurityGroup:
  Type: AWS::EC2::SecurityGroup
  Properties:
    GroupDescription: "awsboxen security group for heka clients"


# The fxa-auth-server webheads, and associated infra.
# These machines are stateless, so we run an auto-scaling group of them

IdpLoadBalancer:
  Type: AWS::ElasticLoadBalancing::LoadBalancer
  Properties:
    AvailabilityZones: {"Fn::GetAZs": ""}
    Listeners:
      - LoadBalancerPort: "80"
        InstancePort: "80"
        Protocol: "HTTP"
    HealthCheck:
      Target: "HTTP:80/__heartbeat__"
      HealthyThreshold: "2"
      UnhealthyThreshold: "2"
      Interval: "10"
      Timeout: "5"


IdpAutoScaleGroup:
  Type: AWS::AutoScaling::AutoScalingGroup
  Properties:
    AvailabilityZones: { "Fn::GetAZs": ""}
    LaunchConfigurationName: { "Ref": "IdpServerLaunchConfig" }
    DesiredCapacity: "10"
    MinSize: "10"
    MaxSize: "10"
    LoadBalancerNames:
      - {"Ref": "IdpLoadBalancer"}
  DependsOn:
    - Cache
    - Database
  UpdatePolicy:
    AutoScalingRollingUpdate:
      MinInstancesInService: "1"
      MaxBatchSize: "1"


IdpServerLaunchConfig:
  Type: AWS::AutoScaling::LaunchConfiguration
  Properties:
    InstanceType: c1.medium
    ImageId: { "Ref": "IdpBoxAMI" }
    KeyName: { "Ref": "AWSBoxDeployKey" }
    SecurityGroups:
      - {"Ref": "IdpServerSecurityGroup"}
      - {"Ref": "HekaClientSecurityGroup"}
    # Cause it to process cloud-init metadata on first run.
    UserData: {"Fn::Base64": {"Fn::Join": ["", [
      "#!/bin/bash\n",
      "set -e -x\n",
      "/opt/aws/bin/cfn-init --region ", {"Ref": "AWS::Region"}, " --stack ", {"Ref": "AWS::StackId"}, " --resource IdpServerLaunchConfig\n",
      "mv /etc/rc.local.post-cloudinit /etc/rc.local\n",
      "exec /etc/rc.local\n",
       ]]}}
  Metadata:
    AWS::CloudFormation::Init:
     config:
       files:
         # This is the .json config file in which the server will look
         # for customizations.  We write it at deploy time because it
         # needs to embed e.g. the public-facing URL, cache server URL, etc.
         /home/app/fxa-auth-server/config/cloud_formation.json:
           content:
             # Public-facing URL, as configured in the DNSRecord.
             public_url: {"Fn::Join": ["", ["http://", {"Fn::Join": [".", ["idp", {"Ref": "DNSPrefix"}, "lcip.org"]]}]]}
             domain: {"Fn::Join": [".", ["idp", {"Ref": "DNSPrefix"}, "lcip.org"]]}
             # Using the RDS MySQL instance for storace
             mysql:
               user: "fxa"
               password: {"Ref": "DBPassword"}
               database: "fxa"
               host: {"Fn::Join": [".", ["db",{"Ref":"DNSPrefix"},"lcip.org"]]}
             # Using the elasticache cluster for short-lived cache data.
             memcached:
               hosts: {"Fn::Join": ["", [
                  {"Fn::GetAtt": ["Cache", "ConfigurationEndpoint.Address"]},
                  ":",
                  {"Fn::GetAtt": ["Cache", "ConfigurationEndpoint.Port"]}
                      ]]}


IdpServerSecurityGroup:
  Type: AWS::EC2::SecurityGroup
  Properties:
    GroupDescription: "awsboxen security group for fxa-auth-server webheads"
    SecurityGroupIngress:
      # Allow ssh from anywhere.
      - IpProtocol: "tcp"
        FromPort: "22"
        ToPort: "22"
        CidrIp: "0.0.0.0/0"
      # Allow access to heka web dashboard.
      - IpProtocol: "tcp"
        FromPort: "4352"
        ToPort: "4352"
        CidrIp: "0.0.0.0/0"


IdpSecurityGroupIngressForLoadBalancer:
  # Allow port 80 ingress from the load balancer.
  # This has to be a separate resource to avoid circular references
  # between IdpLoadBalancer and IdpServerLaunchConfig.
  Type: AWS::EC2::SecurityGroupIngress
  Properties:
    GroupName: {"Ref": "IdpServerSecurityGroup"}
    IpProtocol: "tcp"
    FromPort: "80"
    ToPort: "80"
    SourceSecurityGroupOwnerId: {"Fn::GetAtt": ["IdpLoadBalancer", "SourceSecurityGroup.OwnerAlias"]}
    SourceSecurityGroupName: {"Fn::GetAtt": ["IdpLoadBalancer", "SourceSecurityGroup.GroupName"]}


# The scrypt-helper webheads, and associated infra.
# These machines are stateless, so we run an auto-scaling group of them

ScryptLoadBalancer:
  Type: AWS::ElasticLoadBalancing::LoadBalancer
  Properties:
    AvailabilityZones: {"Fn::GetAZs": ""}
    Listeners:
      - LoadBalancerPort: "80"
        InstancePort: "80"
        Protocol: "HTTP"
    HealthCheck:
      Target: "TCP:80"
      HealthyThreshold: "2"
      UnhealthyThreshold: "2"
      Interval: "10"
      Timeout: "5"


ScryptAutoScaleGroup:
  Type: AWS::AutoScaling::AutoScalingGroup
  Properties:
    AvailabilityZones: { "Fn::GetAZs": ""}
    LaunchConfigurationName: { "Ref": "ScryptServerLaunchConfig" }
    DesiredCapacity: "3"
    MinSize: "3"
    MaxSize: "3"
    LoadBalancerNames:
      - {"Ref": "ScryptLoadBalancer"}
  UpdatePolicy:
    AutoScalingRollingUpdate:
      MinInstancesInService: "1"
      MaxBatchSize: "1"


ScryptServerLaunchConfig:
  Type: AWS::AutoScaling::LaunchConfiguration
  Properties:
    InstanceType: m1.large
    ImageId: { "Ref": "ScryptBoxAMI" }
    KeyName: { "Ref": "AWSBoxDeployKey" }
    SecurityGroups:
      - {"Ref": "ScryptServerSecurityGroup"}
      - {"Ref": "HekaClientSecurityGroup"}
    UserData: {"Fn::Base64": {"Fn::Join": ["", [
      "#!/bin/bash\n",
      "set -e -x\n",
      "mv /etc/rc.local.post-cloudinit /etc/rc.local\n",
      "exec /etc/rc.local\n",
       ]]}}


ScryptServerSecurityGroup:
  Type: AWS::EC2::SecurityGroup
  Properties:
    GroupDescription: "awsboxen security group for scrypt-helper webheads"
    SecurityGroupIngress:
      # Allow ssh from anywhere.
      - IpProtocol: "tcp"
        FromPort: "22"
        ToPort: "22"
        CidrIp: "0.0.0.0/0"
      # Allow access to heka web dashboard.
      - IpProtocol: "tcp"
        FromPort: "4352"
        ToPort: "4352"
        CidrIp: "0.0.0.0/0"


ScryptSecurityGroupIngressForLoadBalancer:
  # Allow port 80 ingress from the load balancer.
  # This has to be a separate resource to avoid circular references.
  Type: AWS::EC2::SecurityGroupIngress
  Properties:
    GroupName: {"Ref": "ScryptServerSecurityGroup"}
    IpProtocol: "tcp"
    FromPort: "80"
    ToPort: "80"
    SourceSecurityGroupOwnerId: {"Fn::GetAtt": ["ScryptLoadBalancer", "SourceSecurityGroup.OwnerAlias"]}
    SourceSecurityGroupName: {"Fn::GetAtt": ["ScryptLoadBalancer", "SourceSecurityGroup.GroupName"]}



# The session-store cache, and supporting infra.
# It's an elasticache store for now, but it might make sense
# to put this on the webheads, or write it into cassandra.

Cache:
  Type: AWS::ElastiCache::CacheCluster
  Properties:
    CacheNodeType: cache.m1.small
    NumCacheNodes: "1"
    Engine: memcached
    CacheSecurityGroupNames:
      - {"Ref": "CacheSecurityGroup"}


CacheSecurityGroup:
  Type: AWS::ElastiCache::SecurityGroup
  Properties:
    Description: "fxa-auth-server webhead session-store cache"


CacheSecurityGroupIngress:
  Type: AWS::ElastiCache::SecurityGroupIngress
  Properties:
    CacheSecurityGroupName: { "Ref": "CacheSecurityGroup"}
    EC2SecurityGroupName: { "Ref": "IdpServerSecurityGroup"}


# The backend database, and supporting infra.
# This is a simple RDS MySQL instance.

Database:
  Type: AWS::RDS::DBInstance
  Properties:
    DBName: "fxa"
    Engine: "MySQL"
    Port: "3306"
    MasterUsername: "fxa"
    MasterUserPassword: {"Ref": "DBPassword"}
    DBInstanceClass: "db.m1.xlarge"
    AllocatedStorage: "20"
    MultiAZ: true
    DBSecurityGroups:
      - {"Ref": "DatabaseSecurityGroup"}


DatabaseSecurityGroup:
  Type: AWS::RDS::DBSecurityGroup
  Properties:
    GroupDescription: "awsboxen security group for fxa-auth-server database"
    DBSecurityGroupIngress:
        - EC2SecurityGroupName: {"Ref": "IdpServerSecurityGroup"}


# A little loads cluster that we can use for running loadtests.
# It's a broker that also acts as a slave, and some additional slave boxes.
# At some point we might use a shared loads cluster, this will do for now.

LoadsBroker:
  Type: AWS::EC2::Instance
  Properties:
    InstanceType: c1.medium
    ImageId: { "Ref": "LoadsBrokerBoxAMI" }
    KeyName: { "Ref": "AWSBoxDeployKey" }
    SecurityGroups:
      - {"Ref": "LoadsClusterSecurityGroup"}
    # Insert the private IP address into the circus.ini file.
    # This ensures the broker gives out correct endpoint addresses.
    UserData: {"Fn::Base64": {"Fn::Join": ["", [
      "#!/bin/bash\n",
      "set -e -x\n",
      "ME=`curl http://169.254.169.254/latest/meta-data/local-ipv4`\n",
      "perl -pi -e 's/0.0.0.0/'$ME'/g' ",
          "/home/app/circus.ini\n",
      "mv /etc/rc.local.post-cloudinit /etc/rc.local\n",
      "exec /etc/rc.local\n",
       ]]}}


LoadsSlaveAutoScaleGroup:
  Type: AWS::AutoScaling::AutoScalingGroup
  Properties:
    AvailabilityZones: { "Fn::GetAZs": ""}
    LaunchConfigurationName: { "Ref": "LoadsSlaveLaunchConfig" }
    DesiredCapacity: "5"
    MinSize: "5"
    MaxSize: "5"
    LoadBalancerNames:
      - {"Ref": "LoadsLoadBalancer"}
  UpdatePolicy:
    AutoScalingRollingUpdate:
      MinInstancesInService: "1"
      MaxBatchSize: "1"
  DependsOn:
    - LoadsBroker


LoadsSlaveLaunchConfig:
  Type: AWS::AutoScaling::LaunchConfiguration
  Properties:
    InstanceType: c1.medium
    ImageId: { "Ref": "LoadsSlaveBoxAMI" }
    KeyName: { "Ref": "AWSBoxDeployKey" }
    SecurityGroups:
      - {"Ref": "LoadsClusterSecurityGroup"}
    UserData: {"Fn::Base64": {"Fn::Join": ["", [
      "#!/bin/bash\n",
      "set -e -x\n",
      "mv /etc/rc.local.post-cloudinit /etc/rc.local\n",
      "exec /etc/rc.local\n",
       ]]}}



LoadsLoadBalancer:
  Type: AWS::ElasticLoadBalancing::LoadBalancer
  Properties:
    AvailabilityZones: {"Fn::GetAZs": ""}
    # Actually we don't need direct access to these boxes.
    # I'm attaching them to a load-balancer because it makes them
    # easier to administer from awsboxen command-line tool.
    Listeners:
      - LoadBalancerPort: "80"
        InstancePort: "80"
        Protocol: "HTTP"


LoadsClusterSecurityGroup:
  Type: AWS::EC2::SecurityGroup
  Properties:
    GroupDescription: "awsboxen security group for loads cluster"
    SecurityGroupIngress:
      # Allow ssh from anywhere.
      - IpProtocol: "tcp"
        FromPort: "22"
        ToPort: "22"
        CidrIp: "0.0.0.0/0"
      # Allow access to heka web dashboard.
      - IpProtocol: "tcp"
        FromPort: "4352"
        ToPort: "4352"
        CidrIp: "0.0.0.0/0"


LoadsClusterSecurityGroupIngressForPeers:
  # Allow peer access to all ports, for ZMQ connectivity.
  # We should lock this down a *little* more.
  Type: AWS::EC2::SecurityGroupIngress
  Properties:
    GroupName: {"Ref": "LoadsClusterSecurityGroup"}
    IpProtocol: "tcp"
    FromPort: "0"
    ToPort: "65535"
    SourceSecurityGroupName: {"Ref": "LoadsClusterSecurityGroup"}
